---
title: "Analyse géocimique de la surface de Mercure à partir des données MESSENGER"
author: "Alexandre Michaux & Beniamino Orsini"
date: "`r Sys.Date()`"
output:
  html_document:
    css: "retro.css"
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide   # <-- code caché par défaut, bouton pour afficher
    df_print: paged
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  echo = FALSE,
  eval = T,
  fig.align = "center",
  fig.width = 7,
  fig.height = 5
)
```

# Présentation du projet

Ce projet s’inscrit dans le cadre du module d’analyse de données et vise à étudier la **composition géochimique de la surface de Mercure** à partir des données orbitales issues de la mission **MESSENGER**.  
L’objectif global est de relier les **hétérogénéités chimiques de surface** à l’**histoire magmatique** et à l’**évolution interne** de la planète.

## La mission MESSENGER

La mission *MESSENGER (MErcury Surface, Space ENvironment, GEochemistry, and Ranging)*, lancée par la NASA en 2004 et mise en orbite autour de Mercure en mars 2011, a fourni jusqu’à 2015 un ensemble complet de données sur la géochimie, la topographie et le champ magnétique de la planète.  
Les données utilisées ici proviennent principalement de deux instruments :

- **XRS (X-Ray Spectrometer)** : mesure des rapports élémentaires de surface (Mg/Si, Al/Si, Ca/Si, Fe/Si, S/Si).  
- **MLA (Mercury Laser Altimeter)** : mesure de la topographie et de l’altitude absolue des terrains.

Ces informations permettent de produire des **cartes globales de composition chimique**, représentatives des terrains volcaniques et de l’évolution du manteau mercurien.

Les données utilisées dans ce projet proviennent principalement de l’instrument XRS (X-Ray Spectrometer) pour la géochimie et de l’instrument MLA (Mercury Laser Altimeter) pour la topographie fournie par la publication de [Nittler *et al.* (2020)](#nittler2020).
	
## Objectifs du projet

Le but de ce travail est double :

1. **Consolider les données MESSENGER** pour obtenir un cube global (latitude × longitude × variable) représentant les principaux rapports géochimiques de la surface de Mercure.
2. **Comparer ces compositions orbitales** à des **expériences de fusion partielle** réalisées en laboratoire (séries Mer8 et Mer15) afin d’en déduire des **cartes globales de pression de fusion** et de **taux de fusion partielle (F)**.
3. Etablir un jeu de données statistiques et cartographiques complet, permettant d’étudier les relations entre composition chimique, topographie.

Cette approche permet de relier chaque pixel de la surface mercurienne à des conditions expérimentales de fusion, et donc à des profondeurs ou degrés de fusion du manteau.

# Préparation et traitement des données

Les données brutes sont constituées de plusieurs fichiers de formats variés (`.bmp`, `.png`, `.dat`, `.rds`), chacun représentant une variable géochimique ou géophysique.  
Avant toute analyse, ces couches sont **uniformisées** et **empilées** dans un **cube tridimensionnel** (latitude × longitude × variable).  
Chaque couche correspond à une carte globale : par exemple, les rapports **Mg/Si**, **Al/Si**, **Ca/Si**, **Fe/Si** et **S/Si**.

Les étapes principales sont les suivantes :

1. **Chargement automatique** des fichiers présents dans le dossier `data/`, avec lecture adaptée selon le format.  
2. **Application de facteurs de correction** pour convertir les intensités (valeurs 0–255 des BMP/PNG) en valeurs normalisées de rapport élémentaire.  
3. **Redimensionnement** de toutes les couches à une grille uniforme de **720 × 1440 pixels** (résolution latitude–longitude).  
4. **Création d’un masque commun** éliminant les pixels invalides (valeurs nulles ou < 0.0001).  
5. **Empilement final** des couches corrigées et masquées dans un objet 3D `result_array_full`, sauvegardé au format `.rds`.

Le code effectue ensuite un contrôle statistique du cube (nombre de pixels valides, distribution des valeurs) et permet une visualisation rapide de chaque couche via la fonction `image()`, dont le titre correspond automatiquement au nom du fichier source.





```{r}
rm(list=ls())

# ==================== PACKAGES ====================
packages <- c("raster","bmp","png","rstudioapi","abind")
installed_packages <- packages %in% installed.packages()[,"Package"]
if (any(!installed_packages)) install.packages(packages[!installed_packages])
lapply(packages, library, character.only = TRUE)

# ==================== CHEMINS ====================
base_path <- dirname(rstudioapi::getSourceEditorContext()$path)
directory_path <- file.path(base_path, "data")
result_file <- file.path(base_path, "result_array_with_uncertainty.rds")

# ==================== UTILS ====================
from03602180 <- function(mat) {
  middle <- dim(mat)[2] / 2
  cbind(mat[, (middle + 1):(2 * middle)], mat[, 1:middle])
}

resize_to_target <- function(mat, target_dim = c(720,1440)) {
  if (is.null(dim(mat))) stop("Matrix has no dimensions.")
  if (all(dim(mat) == target_dim)) return(mat)
  r <- raster::raster(mat)
  r_target <- raster::raster(nrows = target_dim[1], ncols = target_dim[2])
  r_resized <- raster::resample(r, r_target, method = "bilinear")
  as.matrix(r_resized)
}

# ==================== FONCTION DE LECTURE DES COUCHES ====================
process_files_to_3d_array <- function(directory_path, correction_factors = NULL, target_dim = c(720, 1440)) {
  # -------------------------------------------------------
  # Charge BMP / PNG / DAT / RDS d'un dossier,
  # applique une éventuelle correction par fichier,
  # redimensionne à target_dim et empile en tableau 3D.
  # (CSV exclus, tous les RDS inclus)
  # -------------------------------------------------------
  
  # Liste des fichiers, en excluant explicitement CSV et TIFF
  file_list <- list.files(directory_path, full.names = TRUE)
  file_list <- file_list[!grepl("\\.csv$", file_list, ignore.case = TRUE)]
  file_list <- file_list[!grepl("\\.tif(f)?$", file_list, ignore.case = TRUE)]
  # Ne garder que les extensions gérées
  file_list <- file_list[grepl("\\.(bmp|png|dat|rds)$", file_list, ignore.case = TRUE)]
  
  n_files <- length(file_list)
  if (n_files == 0) stop("Aucun fichier pris en charge (BMP/PNG/DAT/RDS) dans : ", directory_path)
  
  layer_names <- basename(file_list)
  array_3d <- array(NA_real_, dim = c(target_dim[1], target_dim[2], n_files))
  
  apply_correction <- function(m, cf) {
    if (is.null(cf)) return(m)
    m * cf
  }
  
  for (i in seq_along(file_list)) {
    file_path <- file_list[i]
    file_name <- layer_names[i]
    ext <- tolower(tools::file_ext(file_name))
    message("→ Lecture de ", file_name)
    
    if (ext == "bmp") {
      # BMP : lecture brute, orientation inchangée
      m <- read.bmp(file_path)
      mode(m) <- "numeric"
      m <- apply_correction(m, correction_factors[[file_name]])
      m <- resize_to_target(m, target_dim)
      array_3d[,,i] <- m
      
    } else if (ext == "png") {
      # PNG : via raster -> matrice ; flip vertical pour redresser
      m <- as.matrix(raster::raster(file_path))
      mode(m) <- "numeric"
      m <- apply_correction(m, correction_factors[[file_name]])
      m <- resize_to_target(m, target_dim)
      m <- m[nrow(m):1, ]  # redressement vertical
      array_3d[,,i] <- m
      
    } else if (ext == "dat") {
      # DAT : structure spéciale -> recollage + (dans ta version) inversion L/C
      m <- from03602180(as.matrix(read.table(file_path, header = FALSE)))
      mode(m) <- "numeric"
      m <- apply_correction(m, correction_factors[[file_name]])
      m <- resize_to_target(m, target_dim)
      array_3d[,,i] <- m
      
    } else if (ext == "rds") {
      # RDS : on prend TOUT fichier .rds
      m <- readRDS(file_path)
      mode(m) <- "numeric"
      m <- apply_correction(m, correction_factors[[file_name]])
      m <- resize_to_target(m, target_dim)
      array_3d[,,i] <- m
      
    } else {
      warning("⚠️ Type non supporté/ignoré : ", file_name)
      next
    }
  }
  
  attr(array_3d, "layer_names") <- layer_names
  array_3d
}
# ==================== FACTEURS DE CORRECTION ====================
correction_factors <- list(
  "mgsi.bmp"    = 0.860023 / 255.0,
  "alsi.bmp"    = 0.402477 / 255.0,
  "ssi.bmp"     = 0.161680 / 255.0,
  "fesi.bmp"    = 0.117737 / 255.0,
  "casi.bmp"    = 0.318000 / 255.0,
  "mgsierr.png" = 0.223226 / 255.0,
  "alsierr.png" = 0.153596 / 255.0,
  "ssierr.png"  = 0.0398775 / 255.0,
  "fesierr.png" = 0.0283532 / 255.0,
  "casierr.png" = 0.0809775 / 255.0
)

# ==================== CONSTRUCTION DU CUBE ====================
result_array <- process_files_to_3d_array(directory_path, correction_factors)
layer_names  <- attr(result_array, "layer_names")

# ==================== MASQUE COMMUN (5 RAPPORTS .bmp) ====================
idx_mgsi <- grep("^mgsi\\.bmp$", layer_names, ignore.case = TRUE)
idx_alsi <- grep("^alsi\\.bmp$", layer_names, ignore.case = TRUE)
idx_casi <- grep("^casi\\.bmp$", layer_names, ignore.case = TRUE)
idx_fesi <- grep("^fesi\\.bmp$", layer_names, ignore.case = TRUE)
idx_ssi  <- grep("^ssi\\.bmp$",  layer_names, ignore.case = TRUE)

if (any(lengths(list(idx_mgsi,idx_alsi,idx_casi,idx_fesi,idx_ssi)) == 0)) {
  stop("❌ Introuvable : au moins une des couches mgsi/alsi/casi/fesi/ssi (.bmp).")
}

# On considère qu’une valeur < 0.0001 = pixel invalide
mask_common <- (result_array[,,idx_mgsi]  > 0.0001) &
  (result_array[,,idx_alsi]  > 0.0001) &
  (result_array[,,idx_casi]  > 0.0001) &
  (result_array[,,idx_fesi]  > 0.0001) &
  (result_array[,,idx_ssi]   > 0.0001)

# ==================== CUBE MASQUÉ (NA sur pixels invalides) ====================
masked_cube <- array(NA_real_, dim = dim(result_array))
for (i in 1:dim(result_array)[3]) {
  L <- result_array[,,i]
  L[!mask_common] <- NA_real_
  masked_cube[,,i] <- L
}

# ==================== CONCATÉNER : ORIGINAL + MASQUÉ ====================
result_array_full <- abind::abind(result_array, masked_cube, along = 3)
attr(result_array_full, "layer_names") <- c(layer_names, paste0(layer_names, "_masked"))

# ==================== STATISTIQUES DES COUCHES ====================
na_counts <- sapply(1:dim(result_array_full)[3], function(i) sum(is.na(result_array_full[,,i])))
layer_info <- data.frame(
  Index = seq_along(attr(result_array_full, "layer_names")),
  Layer = attr(result_array_full, "layer_names"),
  NA_Count = na_counts
)

# ==================== SAUVEGARDE ====================
saveRDS(result_array_full, file = result_file)


result_array_full[result_array_full == 0 | abs(result_array_full) < 1e-10] <- NA_real_
#nombre de NA dans chaque couche
na_counts <- sapply(1:dim(result_array_full)[3], function(i) sum(is.na(result_array_full[,,i])))
layer_info <- data.frame(Index = seq_along(attr(result_array_full, "layer_names")), Layer = attr(result_array_full, "layer_names"), NA_Count = na_counts)
print(layer_info) # Afficher les informations des couches avec le nombre de



get_layer_as_matrix <- function(result_array_full, layer_index) {
  
  if (layer_index < 1 || layer_index > dim(result_array_full)[3]) { #check si l'index est inf. à 1 (index minimum) ou si il est sup. au nombre de couche de result_array
    stop("Layer index out of bounds.")
  }
  return(result_array_full[,,layer_index])   # Extrait et retourne la couche spécifiée sous forme de matrice
}

# === Afficher les cartes élémentaires (indices 1, 3, 7, 10, 12) ===

indices <- c(1, 3, 7, 10, 12)
names <- c("Al/Si", "Ca/Si", "Fe/Si", "Mg/Si", "S/Si")

for (k in seq_along(indices)) {
  i <- indices[k]
  L <- get_layer_as_matrix(result_array_full, i)
  image(
    z = t(apply(L, 2, rev)), 
    main = paste("Carte élémentaire du", names[k]),
    col = terrain.colors(100),
    axes = TRUE,
    xlab = "Longitude",
    ylab = "Latitude"
  )
}


```


## Intégration des données expérimentales

Pour relier les compositions observées à la surface de Mercure à des conditions physiques (pression, température, taux de fusion partielle), deux jeux de données expérimentales sont utilisés :

- **Mer8** et **Mer15**, correspondant à deux compositions de départ différentes du manteau mercurien.  
  Ces expériences de fusion partielle ont été conduites à des pressions de **1.5, 3 et 5 GPa** et des températures comprises entre **1475°C et 1700°C**.

Chaque ligne de ces fichiers (`data_Mer8.csv`, `data_Mer15.csv`) contient :
- la pression expérimentale,
- le taux de fusion partielle (F),
- et les rapports chimiques correspondants (Mg/Si, Al/Si, Ca/Si, Fe/Si, S/Si).

Les deux séries sont combinées pour constituer un ensemble de référence unique (`exp_data`), utilisé pour comparer les compositions de surface pixel par pixel.

```{r}
mer8_path  <- "/Users/alexandremichaux/Documents/UCA/Cours/Analyse des données/TP/TPs/Projet final/data/data_Mer8.csv"
mer15_path <- "/Users/alexandremichaux/Documents/UCA/Cours/Analyse des données/TP/TPs/Projet final/data/data_Mer15.csv"

data_Mer8  <- read.csv(mer8_path,  sep = ",", header = TRUE, check.names = FALSE, stringsAsFactors = FALSE)
data_Mer15 <- read.csv(mer15_path, sep = ",", header = TRUE, check.names = FALSE, stringsAsFactors = FALSE)

# Combiner les deux jeux expérimentaux
exp_data <- rbind(data_Mer8, data_Mer15)
exp_data <- exp_data[complete.cases(exp_data[, c("Mg/Si","Al/Si","Ca/Si","Fe/Si","S/Si")]), ]
```


## Méthode de corrélation géochimique

L’objectif est d’associer chaque pixel de Mercure à la **condition expérimentale la plus proche** parmi les données Mer8/Mer15.  
Pour cela, on calcule pour chaque pixel un **résidu pondéré** mesurant la différence entre la composition observée et la composition expérimentale.

---

### Calcul du résidu pondéré

Pour chaque pixel $(x, y)$, on définit un **vecteur de mesures** :

\[
\mathbf{M}(x, y) = 
\begin{pmatrix}
\mathrm{Mg/Si} \\
\mathrm{Al/Si} \\
\mathrm{Ca/Si} \\
\mathrm{Fe/Si} \\
\mathrm{S/Si}
\end{pmatrix}
\]

et les **incertitudes correspondantes** :

\[
\boldsymbol{\sigma} = 
\begin{pmatrix}
\sigma_{\mathrm{Mg/Si}} \\
\sigma_{\mathrm{Al/Si}} \\
\sigma_{\mathrm{Ca/Si}} \\
\sigma_{\mathrm{Fe/Si}} \\
\sigma_{\mathrm{S/Si}}
\end{pmatrix}
\]

Pour chaque expérience $E_i$ du jeu **Mer8/Mer15**, on calcule le **résidu pondéré** :

\[
R_i = 
\sqrt{
\sum_{k=1}^{5}
\left(
\frac{M_k - E_{i,k}}{\sigma_k}
\right)^2
}
\]

où :
- $M_k$ est la valeur mesurée pour le rapport élémentaire $k$,
- $E_{i,k}$ la valeur correspondante issue de l’expérience $i$,
- $\sigma_k$ l’incertitude associée à la mesure $M_k$.

---

### Sélection de la condition optimale

Le **résidu minimal** est défini par :

\[
R_{\min}(x, y) = \min_i R_i(x, y)
\]

L’expérience $E_i$ associée à $R_{\min}$ correspond à la **condition expérimentale la plus proche**, d’où l’on déduit :
 
- la **pression de fusion partielle** correspondante,
- le **taux de fusion partielle $F$** associé.

Cette minimisation est effectuée **pour chaque pixel valide** de la carte de Mercure.

---

### Cartes pondérées de pression et de fusion

Deux matrices globales sont ainsi générées :

- **`pressure_map`** : carte de la **pression de fusion partielle la plus probable** (en GPa)  
- **`fusion_map`** : carte du **taux de fusion partielle correspondant** (en %)

Ces cartes sont affichées sous forme d’images colorées (`image()`),  
avec :
- l’axe des **abscisses = longitude**,
- l’axe des **ordonnées = latitude**.

Les résultats sont ensuite sauvegardés pour réutilisation dans les étapes suivantes du projet :




```{r}
# ==================== CALCUL DES CARTES DE PRESSION ET DE FUSION ====================
library(plotly)

# --- 1. Chargement des données expérimentales Mer8 et Mer15 ---
mer8_path  <- "/Users/alexandremichaux/Documents/UCA/Cours/Analyse des données/TP/TPs/Projet final/data/data_Mer8.csv"
mer15_path <- "/Users/alexandremichaux/Documents/UCA/Cours/Analyse des données/TP/TPs/Projet final/data/data_Mer15.csv"

data_Mer8  <- read.csv(mer8_path,  sep = ",", header = TRUE, check.names = FALSE, stringsAsFactors = FALSE)
data_Mer15 <- read.csv(mer15_path, sep = ",", header = TRUE, check.names = FALSE, stringsAsFactors = FALSE)

data_Mer8  <- data_Mer8 [complete.cases(data_Mer8 [,  c("Mg/Si","Al/Si","Ca/Si","Fe/Si","S/Si")]), ]
data_Mer15 <- data_Mer15[complete.cases(data_Mer15[, c("Mg/Si","Al/Si","Ca/Si","Fe/Si","S/Si")]), ]

# --- 2. Extraction des couches masquées depuis result_array_full ---
maps <- list(
  MgSi     = get_layer_as_matrix(result_array_full, 24),
  MgSi_err = get_layer_as_matrix(result_array_full, 25),
  AlSi     = get_layer_as_matrix(result_array_full, 15),
  AlSi_err = get_layer_as_matrix(result_array_full, 16),
  CaSi     = get_layer_as_matrix(result_array_full, 17),
  CaSi_err = get_layer_as_matrix(result_array_full, 18),
  FeSi     = get_layer_as_matrix(result_array_full, 21),
  FeSi_err = get_layer_as_matrix(result_array_full, 22),
  SSi      = get_layer_as_matrix(result_array_full, 26),
  SSi_err  = get_layer_as_matrix(result_array_full, 27)
)

nx <- nrow(maps$MgSi)
ny <- ncol(maps$MgSi)

# --- 3. Fonction de calcul du résidu pondéré ---
compute_residual <- function(M, sigma, E) {
  valid <- !is.na(M) & !is.na(sigma)
  if (sum(valid) < 3) return(NA)
  sqrt(sum(((M[valid] - E[valid]) / sigma[valid])^2))
}

# --- 4. Fonction générique pour créer les cartes Pression/Fusion ---
make_maps <- function(exp_data, label) {
  pressure_map <- matrix(NA, nrow = nx, ncol = ny)
  fusion_map   <- matrix(NA, nrow = nx, ncol = ny)

  for (x in 1:nx) {
    for (y in 1:ny) {
      M <- c(maps$MgSi[x, y], maps$AlSi[x, y], maps$CaSi[x, y],
             maps$FeSi[x, y], maps$SSi[x, y])
      sigma <- c(maps$MgSi_err[x, y], maps$AlSi_err[x, y], maps$CaSi_err[x, y],
                 maps$FeSi_err[x, y], maps$SSi_err[x, y])
      if (all(is.na(M))) next

      residuals <- apply(exp_data[, c("Mg/Si", "Al/Si", "Ca/Si", "Fe/Si", "S/Si")], 1, function(E) {
        compute_residual(M, sigma, E)
      })

      best_index <- which.min(residuals)
      if (is.na(best_index)) next

      pressure_map[x, y] <- exp_data$Pression[best_index]
      fusion_map[x, y]   <- exp_data$F[best_index]
    }
  }

  return(list(pressure = pressure_map, fusion = fusion_map))
}

# --- 5. Exécution pour chaque jeu expérimental ---
maps_Mer8  <- make_maps(data_Mer8,  "Mer8")
maps_Mer15 <- make_maps(data_Mer15, "Mer15")

# --- 7. Ajout des 4 cartes au cube principal ---
result_array_full <- abind::abind(
  result_array_full,
  maps_Mer8$pressure,
  maps_Mer8$fusion,
  maps_Mer15$pressure,
  maps_Mer15$fusion,
  along = 3
)

# Mise à jour des noms des couches
attr(result_array_full, "layer_names") <- c(
  attr(result_array_full, "layer_names"),
  "pressure_Mer8", "fusion_Mer8", "pressure_Mer15", "fusion_Mer15"
)

# --- 8. Sauvegarde du cube complet ---
saveRDS(result_array_full, file = result_file)





# Exemple d’extraction
pressure_Mer8  <- get_layer_as_matrix(result_array_full,29)
fusion_Mer8    <- get_layer_as_matrix(result_array_full,30)
pressure_Mer15 <- get_layer_as_matrix(result_array_full, 31)
fusion_Mer15   <- get_layer_as_matrix(result_array_full, 32)


# Titres à afficher pour chaque couche
titles <- c("pressure_Mer8", "fusion_Mer8", "pressure_Mer15", "fusion_Mer15")

# Boucle sur les indices correspondants
for (i in 1:4) {
  L <- get_layer_as_matrix(result_array_full, 28 + i)  # 29 → 32
  
  image(
    z = t(apply(L, 2, rev)),      # rotation correcte pour affichage
    main = titles[i],             # titre personnalisé
    col = terrain.colors(100),
    axes = TRUE,
    xlab = "Longitude",
    ylab = "Latitude"
  )
}

```
Afin d’évaluer la dispersion et la précision des rapports géochimiques mesurés par MESSENGER, on réalise une analyse statistique globale des cinq rapports élémentaires (Mg/Si, Al/Si, Ca/Si, Fe/Si, S/Si).

Chaque distribution est représentée par un boxplot indiquant la variabilité spatiale des valeurs mesurées à la surface de Mercure.
Les barres d’erreur superposées représentent les incertitudes moyennes ±1σ issues des cartes d’erreur correspondantes.

Cette visualisation permet de comparer directement la stabilité relative de chaque rapport ainsi que le niveau de bruit instrumental affectant les mesures.
```{r}
# ==================== BOXPLOTS CLASSIQUES + INCERTITUDES SUPERPOSÉES ====================

# --- 1. Données à partir de ton objet maps ---
ratios <- c("MgSi", "AlSi", "CaSi", "FeSi", "SSi")

df <- do.call(rbind, lapply(ratios, function(r) {
  vals <- as.vector(maps[[r]])
  errs <- as.vector(maps[[paste0(r, "_err")]])
  data.frame(
    Ratio = r,
    Value = vals,
    Error = errs
  )
}))

df <- df[complete.cases(df), ]

# --- 2. Calcul de statistiques par rapport ---
library(dplyr)
err_summary <- df %>%
  group_by(Ratio) %>%
  summarise(
    mean_val = mean(Value, na.rm = TRUE),
    mean_err = mean(Error, na.rm = TRUE),
    sd_err   = sd(Error, na.rm = TRUE)
  )

# --- 3. Couleurs pour les boxplots et les symboles d’erreur ---
cols_box <- c("darkorange", "steelblue", "seagreen3", "indianred3", "goldenrod")
cols_err <- c("chocolate3", "navy", "forestgreen", "darkred", "darkgoldenrod4")

# --- 4. Tracé des boxplots normaux ---
boxplot(Value ~ Ratio, data = df,
        col = cols_box,
        border = "gray30",
        ylab = "Rapport élémentaire (X/Si)",
        main = "Distribution des rapports élémentaires avec incertitudes",
        outline = FALSE,
        las = 1,
        cex.axis = 0.9)

# --- 5. Superposition des incertitudes moyennes (autre couleur / symbole) ---
# Positions x des boxplots (1:5)
xpos <- 1:length(ratios)

# Points = moyennes, barres = ± écart-type des erreurs
points(xpos, err_summary$mean_val, 
       pch = 21, bg = "white", col = "black", cex = 1.3, lwd = 1.5)
arrows(xpos,
       err_summary$mean_val - err_summary$mean_err,
       xpos,
       err_summary$mean_val + err_summary$mean_err,
       angle = 90, code = 3, length = 0.08, lwd = 2, col = cols_err)

# --- 6. Légende claire ---
legend("topleft",
       legend = c("Distribution (boxplot)", "Incertitude moyenne ±1σ(err)"),
       pch = c(15, 21),
       pt.bg = c(cols_box[1], "white"),
       col = c("gray30", "black"),
       lwd = c(0, 2),
       pt.cex = c(1.8, 1.3),
       bty = "n")
```
Pour comprendre comment la composition varie selon les provinces géologiques, on compare ici la distribution régionale et la distribution globale de chaque rapport élémentaire.

Les courbes supérieures représentent les distributions propres à chaque région (zones riches en magnésium, plaines riches en aluminium, bassin de Caloris, etc.), tandis que les courbes inférieures indiquent la distribution globale de la planète.

Cette approche met en évidence les contrastes géochimiques régionaux et permet d’évaluer la variabilité intra-régionale par rapport à la composition moyenne de Mercure
```{r}
# ==================== DISTRIBUTIONS RÉGIONALES/GLOBALES — FIGURES SÉPARÉES ====================

# --- Packages ---
if (!require(patchwork)) install.packages("patchwork")
library(ggplot2)
library(dplyr)
library(patchwork)

# --- 1. Données ---
maps <- list(
  MgSi = get_layer_as_matrix(result_array_full, 24),
  AlSi = get_layer_as_matrix(result_array_full, 15),
  CaSi = get_layer_as_matrix(result_array_full, 17),
  FeSi = get_layer_as_matrix(result_array_full, 21),
  SSi  = get_layer_as_matrix(result_array_full, 26)
)

region_map   <- get_layer_as_matrix(result_array_full, 28)
region_vals  <- c(1,2,3,4,5,6)
region_names <- c("High-Mg","Al-rich","Caloris","Rach","High-Al NVP","Low-Al NVP")
Region <- factor(as.vector(region_map), levels = region_vals, labels = region_names)

ratios <- names(maps)
df <- do.call(rbind, lapply(ratios, function(r){
  data.frame(Ratio = r, Value = as.vector(maps[[r]]), Region = Region)
})) |> na.omit()

# --- 2. Palette géologique ---
cols_base <- c(
  "High-Mg"="#E4572E", "Al-rich"="#17BEBB", "Caloris"="#FFC914",
  "Rach"="#4B4E6D", "High-Al NVP"="#76B041", "Low-Al NVP"="#A23B72"
)

# --- 3. Fonction pour créer un couple avec légende ---
make_pair <- function(r){
  d  <- df[df$Ratio==r, ]
  xr <- range(d$Value, na.rm = TRUE)
  
  # Distribution régionale
  p_reg <- ggplot(d, aes(Value, fill=Region, color=Region)) +
    geom_density(alpha=.35, linewidth=1, adjust=1.2) +
    scale_fill_manual(values=cols_base, name="Régions géologiques") +
    scale_color_manual(values=cols_base, guide="none") +
    scale_x_continuous(limits = xr) +
    labs(title=paste("Distribution régionale de", r), x=NULL, y="Densité") +
    theme_minimal(base_size=12) +
    theme(
      plot.title = element_text(face="bold", hjust=.5),
      axis.text.x = element_blank(),
      axis.ticks.x = element_blank(),
      panel.grid.minor = element_blank(),
      legend.position = "bottom"
    )
  
  # Distribution globale
  p_glb <- ggplot(d, aes(Value)) +
    geom_density(fill="#CCCCCC", color="#444444", alpha=.6, linewidth=1.1, adjust=1.2) +
    scale_x_continuous(limits = xr) +
    labs(title=paste("Distribution globale de", r), x=r, y="Densité") +
    theme_minimal(base_size=12) +
    theme(
      plot.title = element_text(face="bold", hjust=.5),
      panel.grid.minor = element_blank(),
      legend.position = "none"
    )
  
  # Empilement vertical avec légende commune
  p_reg / p_glb + plot_layout(heights = c(1, 1), guides = "collect") &
    theme(
      legend.position = "bottom",
      legend.justification = "center",
      legend.text = element_text(size = 10),
      legend.title = element_text(face = "bold")
    )
}



# --- Option : Export individuel ---
# ggsave(paste0("distribution_", r, ".png"), pairs[[i]], width = 8, height = 6, dpi = 300)
```

```{r}
# ==================== CARTES D'ANOMALIES NORMALISÉES (ggplot2 + grille 60°/30°) ====================

library(ggplot2)
library(dplyr)
library(tidyr)
library(grid)  # pour unit()

# 1) Extraire les couches
ratios <- list(
  MgSi = get_layer_as_matrix(result_array_full, 24),
  AlSi = get_layer_as_matrix(result_array_full, 15),
  CaSi = get_layer_as_matrix(result_array_full, 17),
  FeSi = get_layer_as_matrix(result_array_full, 21),
  SSi = get_layer_as_matrix(result_array_full, 26)
)

nx <- nrow(ratios$MgSi); ny <- ncol(ratios$MgSi)
lon <- seq(-180, 180, length.out = ny)
lat <- seq(  90, -90, length.out = nx)

to_df <- function(mat, name){
  M  <- t(mat)                              # transposée pour bonne orientation
  mu <- mean(M, na.rm = TRUE)
  sdv <- sd(M, na.rm = TRUE)
  Z  <- (M - mu) / sdv
  Z[Z >  3] <-  3
  Z[Z < -3] <- -3
  expand.grid(Lon = lon, Lat = lat) |>
    mutate(Value = as.vector(Z), Ratio = name)
}

df_all <- do.call(rbind, lapply(names(ratios), \(r) to_df(ratios[[r]], r)))
df_all <- df_all[complete.cases(df_all), ]

# 2) Lignes de grille (60° lon / 30° lat)
grid_long <- seq(-180, 180, by = 60)
grid_lat  <- seq( -90,  90, by = 30)

grid_lon_df <- do.call(rbind, lapply(grid_long, \(L) data.frame(Lon = L,   Lat = lat, type = "lon")))
grid_lat_df <- do.call(rbind, lapply(grid_lat,  \(B) data.frame(Lon = lon, Lat = B,   type = "lat")))
grid_lines  <- rbind(grid_lon_df, grid_lat_df)

# 3) Palette
pal <- c("#08306B","#2171B5","#DEEBF7","#FEE0D2","#CB181D","#67000D")

# 4) Plot
ggplot(df_all, aes(Lon, Lat, fill = Value)) +
  geom_raster(interpolate = TRUE) +
  # grilles PAR-DESSUS, sans hériter des aes du raster
  geom_path(
    data = grid_lines[grid_lines$type == "lon", ],
    aes(x = Lon, y = Lat, group = Lon),
    inherit.aes = FALSE, color = "gray35", linewidth = 0.35, alpha = 0.9
  ) +
  geom_path(
    data = grid_lines[grid_lines$type == "lat", ],
    aes(x = Lon, y = Lat, group = Lat),
    inherit.aes = FALSE, color = "gray35", linewidth = 0.35, alpha = 0.9
  ) +
  scale_fill_gradientn(
    colors = pal, limits = c(-3, 3), breaks = seq(-3, 3, 1),
    name = "Z-score", oob = scales::squish
  ) +
  scale_x_continuous(breaks = grid_long) +
  scale_y_continuous(breaks = grid_lat) +
  coord_equal(xlim = c(-180, 180), ylim = c(-90, 90), expand = FALSE) +
  facet_wrap(~ Ratio, ncol = 3) +
  labs(title = "Cartes d’anomalies normalisées (Z-score)",
       x = "Longitude (°)", y = "Latitude (°)") +
  theme_minimal(base_size = 13) +
  theme(
    plot.title   = element_text(face = "bold", size = 16, hjust = 0.5),
    strip.text   = element_text(face = "bold", size = 13),
    axis.title   = element_text(face = "bold"),
    axis.text    = element_text(color = "gray20"),
    panel.grid   = element_blank(),                 # on gère la grille nous-mêmes
    panel.border = element_rect(color = "gray50", fill = NA, linewidth = 0.4),
    legend.position = "bottom",
    legend.key.width = unit(2.5, "cm"),
    legend.title = element_text(face = "bold")
  )

```

```{r}
# ==================== DISTRIBUTIONS DENSITÉ & DEM (régions + globales séparées) ====================

# --- Installation et chargement des packages nécessaires ---
if (!require(patchwork)) install.packages("patchwork")
library(patchwork)
library(ggplot2)
library(dplyr)

# --- 1. Extraction des couches ---
Density <- get_layer_as_matrix(result_array_full, 20)  # DensityGrid.dat_masked
DEM     <- get_layer_as_matrix(result_array_full, 19)  # DEM.RDS_masked
region_map <- get_layer_as_matrix(result_array_full, 28)

# --- 2. Définition des régions ---
region_values <- c(1, 2, 3, 4, 5, 6)
region_names  <- c("High-Mg", "Al-rich", "Caloris", "Rach", "High-Al NVP", "Low-Al NVP")

# --- 3. Construction du dataframe principal ---
Region <- factor(as.vector(region_map), levels = region_values, labels = region_names)
df <- data.frame(
  Density = as.vector(Density),
  DEM     = as.vector(DEM),
  Region  = Region
) |> na.omit()

# --- 4. Palette harmonieuse ---
cols_base <- c(
  "High-Mg"     = "#E4572E",  # orange
  "Al-rich"     = "#17BEBB",  # turquoise
  "Caloris"     = "#FFC914",  # jaune
  "Rach"        = "#4B4E6D",  # bleu-gris
  "High-Al NVP" = "#76B041",  # vert clair
  "Low-Al NVP"  = "#A23B72"   # magenta
)

# === FIGURE 1 : DENSITY ===

## A. DENSITY par région
p_density_region <- ggplot(df, aes(x = Density, fill = Region, color = Region)) +
  geom_density(alpha = 0.35, linewidth = 1.0, adjust = 1.2) +
  scale_fill_manual(values = cols_base, name = "Régions géologiques") +
  scale_color_manual(values = cols_base, guide = "none") +
  labs(title = "Distribution régionale de la densité",
       x = NULL, y = "Densité de probabilité") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "bottom",
    legend.justification = "center",
    legend.text = element_text(size = 10),
    legend.title = element_text(face = "bold")
  )

## B. DENSITY globale
p_density_global <- ggplot(df, aes(x = Density)) +
  geom_density(fill = "#A23B72", color = "#7A2853", alpha = 0.4, linewidth = 1.1) +
  labs(title = "Distribution globale de la densité",
       x = "Densité (unités relatives)", y = "Densité de probabilité") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

## Combinaison verticale avec légende commune
plot_density <- p_density_region / p_density_global +
  plot_layout(heights = c(1, 0.6), guides = "collect") &
  theme(
    legend.position = "bottom",
    legend.justification = "center",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10)
  )

plot_density  # <-- Affiche la figure DENSITY avec légende


# === FIGURE 2 : DEM ===

## C. DEM par région
p_dem_region <- ggplot(df, aes(x = DEM, fill = Region, color = Region)) +
  geom_density(alpha = 0.35, linewidth = 1.0, adjust = 1.2) +
  scale_fill_manual(values = cols_base, name = "Régions géologiques") +
  scale_color_manual(values = cols_base, guide = "none") +
  labs(title = "Distribution régionale de l'altitude (DEM)",
       x = NULL, y = "Densité de probabilité") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "bottom",
    legend.justification = "center",
    legend.text = element_text(size = 10),
    legend.title = element_text(face = "bold")
  )

## D. DEM global
p_dem_global <- ggplot(df, aes(x = DEM)) +
  geom_density(fill = "#999999", color = "#555555", alpha = 0.4, linewidth = 1.1) +
  labs(title = "Distribution globale de l'altitude",
       x = "Altitude (m)", y = "Densité de probabilité") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

## Combinaison verticale avec légende commune
plot_dem <- p_dem_region / p_dem_global +
  plot_layout(heights = c(1, 0.6), guides = "collect") &
  theme(
    legend.position = "bottom",
    legend.justification = "center",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 10)
  )

plot_dem  # <-- Affiche la figure DEM avec légende
```




# Références

<a id="nittler2020"></a>
Nittler, L.R., Frank, E.A., Weider, S.Z., Crapster-Pregont, E., Vorburger, A., Starr, R.D. &
Solomon, S.C., 2020. global major-element maps of Mercury from four years of MESSENGER
X-Ray Spectrometer observations. Icarus, 345, 113716. https://doi.org/10.1016/j.icarus.2020.113716.



